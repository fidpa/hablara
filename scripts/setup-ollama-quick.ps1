#Requires -Version 5.1
<#
.SYNOPSIS
    Hablara - Ollama Quick-Setup Script (Windows)

.DESCRIPTION
    One-liner installation of Ollama + optimized model for Hablara.

    This script:
    1. Checks disk space (10 GB minimum)
    2. Installs Ollama (via winget or manual download)
    3. Starts Ollama server
    4. Downloads qwen2.5:7b model (~4.7 GB)
    5. Creates qwen2.5:7b-custom with optimized parameters
    6. Verifies installation

.EXAMPLE
    .\scripts\setup-ollama-quick.ps1

.NOTES
    Exit Codes:
      0 - Success
      1 - General error
      2 - Insufficient disk space
      3 - Network error
      4 - Platform not supported (not Windows)

    Requirements:
      - Windows 10/11
      - 10 GB free disk space
      - Internet connection

    Author: HablarÃ¡ Team
    Created: 2026-02-04
    Changed: 2026-02-04
#>

[CmdletBinding()]
param()

# Strict mode
Set-StrictMode -Version Latest
$ErrorActionPreference = 'Stop'

# Error handler for unexpected failures
trap {
    Write-Host "[X] Setup failed unexpectedly: $_" -ForegroundColor Red
    exit 1
}

# Configuration
$ScriptVersion = '1.0.0'
$RequiredDiskSpaceGB = 10
$ModelName = 'qwen2.5:7b'
$CustomModelName = 'qwen2.5:7b-custom'
$OllamaApiUrl = 'http://localhost:11434'

# Logging functions
function Write-LogInfo {
    param([string]$Message)
    Write-Host "[i] $Message" -ForegroundColor Blue
}

function Write-LogSuccess {
    param([string]$Message)
    Write-Host "[OK] $Message" -ForegroundColor Green
}

function Write-LogWarning {
    param([string]$Message)
    Write-Host "[!] $Message" -ForegroundColor Yellow
}

function Write-LogError {
    param([string]$Message)
    Write-Host "[X] $Message" -ForegroundColor Red
}

# Check if command exists
function Test-CommandExists {
    param([string]$Command)
    $null -ne (Get-Command $Command -ErrorAction SilentlyContinue)
}

# Get available disk space in GB
function Get-FreeDiskSpaceGB {
    $ollamaPath = Join-Path $env:USERPROFILE '.ollama'
    if (-not (Test-Path $ollamaPath)) {
        $ollamaPath = $env:USERPROFILE
    }

    $drive = (Get-Item $ollamaPath).PSDrive.Name
    $disk = Get-PSDrive -Name $drive
    [math]::Floor($disk.Free / 1GB)
}

# Wait for Ollama server
function Wait-OllamaServer {
    param([int]$MaxAttempts = 30)

    Write-LogInfo "Waiting for Ollama server..."

    for ($attempt = 1; $attempt -le $MaxAttempts; $attempt++) {
        try {
            $response = Invoke-RestMethod -Uri "$OllamaApiUrl/api/version" -TimeoutSec 2 -ErrorAction Stop
            Write-LogSuccess "Ollama server is ready"
            return $true
        } catch {
            Start-Sleep -Seconds 1
        }
    }

    Write-LogError "Ollama server not responding after $MaxAttempts seconds"
    return $false
}

# Start Ollama server
function Start-OllamaServer {
    # Check if already running
    try {
        $response = Invoke-RestMethod -Uri "$OllamaApiUrl/api/version" -TimeoutSec 2 -ErrorAction Stop
        Write-LogInfo "Ollama server already running"
        return $true
    } catch {
        # Not running, try to start
    }

    # Try starting as background process
    if (Test-CommandExists 'ollama') {
        Write-LogInfo "Starting Ollama server..."
        Start-Process -FilePath 'ollama' -ArgumentList 'serve' -WindowStyle Hidden
        return Wait-OllamaServer
    }

    return $false
}

# Install Ollama
function Install-Ollama {
    if (Test-CommandExists 'ollama') {
        Write-LogSuccess "Ollama already installed"

        # Show version
        $version = & ollama --version 2>&1 | Select-Object -First 1
        Write-LogInfo "Version: $version"

        # Ensure server is running
        if (-not (Start-OllamaServer)) {
            Write-LogError "Failed to start Ollama server"
            Write-LogInfo "Please start manually: ollama serve"
            exit 1
        }

        return
    }

    Write-LogInfo "Installing Ollama..."

    # Try winget first
    if (Test-CommandExists 'winget') {
        Write-LogInfo "Using winget for installation..."

        try {
            & winget install Ollama.Ollama --silent --accept-source-agreements --accept-package-agreements

            # Exit code 3010 = success but reboot required
            if ($LASTEXITCODE -eq 0 -or $LASTEXITCODE -eq 3010) {
                Write-LogSuccess "Ollama installed via winget"
                if ($LASTEXITCODE -eq 3010) {
                    Write-LogWarning "A reboot may be required to complete installation"
                }

                # Refresh PATH
                $env:Path = [System.Environment]::GetEnvironmentVariable("Path", "Machine") + ";" + [System.Environment]::GetEnvironmentVariable("Path", "User")

                # Start server
                Start-OllamaServer
                return
            }
        } catch {
            Write-LogWarning "winget installation failed: $_"
        }
    }

    # Manual installation instructions
    Write-LogWarning "Automatic installation not available"
    Write-Host ""
    Write-Host "========================================" -ForegroundColor Yellow
    Write-Host ""
    Write-Host "Please install Ollama manually:" -ForegroundColor Cyan
    Write-Host ""
    Write-Host "  1. Download from: https://ollama.ai/download"
    Write-Host "  2. Run the installer"
    Write-Host "  3. Run this script again"
    Write-Host ""
    Write-Host "Alternative (winget):"
    Write-Host "  winget install Ollama.Ollama"
    Write-Host ""
    exit 1
}

# Pull base model
function Install-BaseModel {
    Write-LogInfo "Checking model: $ModelName"

    # Check if model exists (escape regex special chars in model name)
    $models = & ollama list 2>$null
    $escapedModelName = [regex]::Escape($ModelName)
    if ($models -match "^$escapedModelName\s") {
        Write-LogSuccess "Model already available: $ModelName"
        return
    }

    Write-LogInfo "Downloading $ModelName (~4.7GB, takes 2-5min)..."

    & ollama pull $ModelName
    if ($LASTEXITCODE -ne 0) {
        Write-LogError "Model download failed"
        Write-LogInfo "Please try manually: ollama pull $ModelName"
        exit 1
    }

    Write-LogSuccess "Model downloaded: $ModelName"
}

# Create custom model
function New-CustomModel {
    Write-LogInfo "Checking custom model: $CustomModelName"

    # Check if custom model exists (escape regex special chars in model name)
    $models = & ollama list 2>$null
    $escapedCustomModelName = [regex]::Escape($CustomModelName)
    if ($models -match "^$escapedCustomModelName\s") {
        Write-LogSuccess "Custom model already available"
        return
    }

    Write-LogInfo "Creating optimized custom model..."

    # Create temporary Modelfile
    $modelfileContent = @"
FROM qwen2.5:7b

# Optimized parameters for Hablara emotion/fallacy detection
PARAMETER temperature 0.3
PARAMETER top_p 0.9
PARAMETER repeat_penalty 1.1

# System message for Hablara
SYSTEM You are an expert in psychology, communication analysis, and logical reasoning. Analyze text for emotions, cognitive biases, and logical fallacies with high accuracy.
"@

    $modelfilePath = Join-Path $env:TEMP 'hablara-modelfile'
    $modelfileContent | Out-File -FilePath $modelfilePath -Encoding UTF8

    try {
        & ollama create $CustomModelName -f $modelfilePath
        if ($LASTEXITCODE -ne 0) {
            Write-LogWarning "Custom model creation failed"
            Write-LogWarning "Continuing with base model"
            return
        }

        Write-LogSuccess "Custom model created: $CustomModelName"
        Write-LogInfo "Accuracy boost: 80% -> 93% (Emotion Detection)"
    } finally {
        # Cleanup temp file
        Remove-Item -Path $modelfilePath -ErrorAction SilentlyContinue
    }
}

# Verify installation
function Test-Installation {
    Write-Host ""
    Write-LogInfo "Verifying installation..."

    # Check Ollama binary
    if (-not (Test-CommandExists 'ollama')) {
        Write-LogError "Ollama binary not found"
        return $false
    }

    # Check server API
    try {
        $null = Invoke-RestMethod -Uri "$OllamaApiUrl/api/version" -TimeoutSec 5
    } catch {
        Write-LogError "Ollama server not reachable"
        Write-LogInfo "Start manually: ollama serve"
        return $false
    }

    # Check base model (escape regex special chars in model names)
    $models = & ollama list 2>$null
    $escapedModelName = [regex]::Escape($ModelName)
    $escapedCustomModelName = [regex]::Escape($CustomModelName)
    if (-not ($models -match "^$escapedModelName\s")) {
        Write-LogError "Base model not found: $ModelName"
        return $false
    }

    Write-LogSuccess "Base model available: $ModelName"

    # Check custom model (optional)
    if ($models -match "^$escapedCustomModelName\s") {
        Write-LogSuccess "Custom model available: $CustomModelName"
    } else {
        Write-LogWarning "Custom model not available (using base model)"
    }

    Write-Host ""
    Write-LogSuccess "Setup complete!"

    return $true
}

# Pre-flight checks
function Test-Prerequisites {
    Write-Host ""
    Write-Host "Hablara Ollama Quick-Setup v$ScriptVersion" -ForegroundColor Cyan
    Write-Host "========================================" -ForegroundColor Cyan
    Write-Host ""

    # Check platform
    if ($env:OS -ne 'Windows_NT') {
        Write-LogError "This script is for Windows only"
        Write-LogInfo "For macOS/Linux: ./scripts/setup-ollama-quick.sh"
        exit 4
    }

    # Check disk space
    $freeSpace = Get-FreeDiskSpaceGB

    if ($freeSpace -lt $RequiredDiskSpaceGB) {
        Write-LogError "Insufficient disk space"
        Write-LogError "Required: ${RequiredDiskSpaceGB}GB, Available: ${freeSpace}GB"
        exit 2
    }

    Write-LogSuccess "Disk space: ${freeSpace}GB available"

    # Check network
    try {
        $null = Invoke-WebRequest -Uri 'https://ollama.ai' -TimeoutSec 5 -UseBasicParsing
        Write-LogSuccess "Network connection OK"
    } catch {
        Write-LogError "No network connection to ollama.ai"
        Write-LogInfo "Please check your internet connection"
        exit 3
    }

    Write-Host ""
}

# Main function
function Main {
    # Run pre-flight checks
    Test-Prerequisites

    # Install Ollama
    Install-Ollama

    # Pull base model
    Install-BaseModel

    # Create custom model
    New-CustomModel

    # Verify everything works
    if (-not (Test-Installation)) {
        exit 1
    }

    # Success message
    Write-Host "========================================" -ForegroundColor Cyan
    Write-Host ""
    Write-Host "Next steps:" -ForegroundColor Green
    Write-Host ""
    Write-Host "  1. Start Hablara.exe"
    Write-Host "  2. Press Ctrl+Shift+D for first recording"
    Write-Host "  3. Allow microphone permission (one-time)"
    Write-Host ""
    Write-Host "LLM Settings in the app:" -ForegroundColor Yellow
    Write-Host "  - Provider: Ollama (default)"
    Write-Host "  - Model: qwen2.5:7b-custom"
    Write-Host "  - Base URL: http://localhost:11434"
    Write-Host ""
    Write-Host "Documentation: https://github.com/fidpa/hablara/blob/main/README.md" -ForegroundColor Blue
    Write-Host ""
}

# Run main
Main

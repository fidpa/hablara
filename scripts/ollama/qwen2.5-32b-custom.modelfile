# Qwen 2.5 32B Instruct - Optimiert für Hablará (Voice Intelligence Pipeline)
#
# Quality Tier: Q1 (Recommended Mid-Tier)
# Improvements vs 7B:
# - +8% MMLU (83.1% vs 74.8%)
# - +2% JSON Validity (94% vs 92%)
# - +10% Reasoning for cognitive distortions
# - Better long-context understanding
#
# Performance-Erwartung auf M4 Pro:
# - Emotion Analysis: ~3.5s (vs. ~2.2s mit 7B)
# - Fallacy Detection: ~7.0s (vs. ~4.3s mit 7B)
# - JSON Reliability: 94%
#
# RAM Requirement: ~20 GB (Q4 quantization)
#
# Usage:
#   ollama pull qwen2.5:32b
#   ollama create qwen2.5:32b-custom -f qwen2.5-32b-custom.modelfile
#   ollama run qwen2.5:32b-custom

FROM qwen2.5:32b

# Context Window: 8K ausreichend für Hablará
PARAMETER num_ctx 8192

# Temperature: 0.3 für strukturierte Outputs
PARAMETER temperature 0.3

# Top-p: 0.9 für Nucleus Sampling
PARAMETER top_p 0.9

# Repeat Penalty: Verhindert Halluzination-Loops
PARAMETER repeat_penalty 1.1

# System Message: Hablará-Context (V2 - format-neutral, JSON via API-Parameter)
SYSTEM """Du bist ein KI-Assistent für die Hablará Voice Intelligence Platform.

Deine Aufgaben:
1. Textanalyse: Emotionen, Argumente, Tonalität und psychologische Muster erkennen
2. Wissensassistenz: Fragen zu Hablará-Features beantworten

Wichtig:
- Sei präzise und objektiv
- Berücksichtige deutschen Sprachgebrauch und Kultur
- Folge dem im Prompt angegebenen Antwortformat (JSON oder natürliche Sprache)
- Keine Halluzinationen oder erfundene Details
"""

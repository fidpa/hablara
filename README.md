# HablarÃ¡ â€“ â€Er/sie wird sprechen"

> **Finde heraus, was du sagst**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-1.1.1-blue.svg)][releases]
[![Platform](https://img.shields.io/badge/platform-macOS%20%7C%20Windows%20%7C%20Linux-lightgrey.svg)][releases]
[![Stack](https://img.shields.io/badge/stack-Tauri%202.0%20%7C%20Next.js%2014%20%7C%20Rust%201.70+-blue.svg)](https://tauri.app/)
[![Homebrew](https://img.shields.io/badge/homebrew-tap-orange?logo=homebrew)](https://github.com/fidpa/homebrew-hablara)

Desktop-App fÃ¼r Selbstreflexion mit Spracherkennung und KI-gestÃ¼tzter Sprachanalyse.

Transkription erfolgt lokal (whisper.cpp).

Sprachanalyse wahlweise lokal (Ollama) oder via Cloud (OpenAI/Anthropic).

![HablarÃ¡ Welcome Screen](public/pictures/welcome-screen.png)

## Inhalt

- [Plattformen](#plattformen)
- [Installation](#installation)
- [Funktionen](#funktionen)
- [Architektur](#architektur)
- [Datenschutz](#datenschutz)
- [Vergleich](#vergleich)
- [Mitwirken](#mitwirken)
- [Lizenz](#lizenz)

---

## Plattformen

| Plattform | Status | Architektur | Hinweise |
|----------|--------|--------------|-------|
| **macOS** | âœ… VerfÃ¼gbar | ARM64 (Apple Silicon) | MLX-Whisper verfÃ¼gbar |
| **macOS** | âœ… VerfÃ¼gbar | x86_64 (Intel) | Nur whisper.cpp |
| **Windows** | âœ… VerfÃ¼gbar | x86_64 | whisper.cpp CPU, kein MLX, WASAPI Audio |
| **Linux** | âœ… VerfÃ¼gbar | x86_64 | Ubuntu 20.04+, .deb/.rpm/.AppImage |

> **Hinweis:** macOS (ARM64) ist die primÃ¤re Entwicklungsplattform.

### Feature-VerfÃ¼gbarkeit nach Plattform

| Feature | macOS ARM64 | macOS x64 | Windows x64 | Linux x64 |
|---------|-------------|-----------|-------------|-----------|
| whisper.cpp | âœ… | âœ… | âœ… | âœ… |
| MLX-Whisper | âœ… | âŒ | âŒ | âŒ |
| Ollama LLM | âœ… | âœ… | âœ… | âœ… |
| OpenAI/Anthropic | âœ… | âœ… | âœ… | âœ… |
| Global Hotkey | âœ… | âœ… | âœ… | âœ… |
| Native Audio | CoreAudio | CoreAudio | WASAPI | ALSA/PipeWire |
| API Key Storage | Keychain | Keychain | Credential Manager | Secret Service |

---

## Installation

**Hinweis:** Ohne LLM-Anbieter funktioniert nur die Transkription. Alle psychologischen Features benÃ¶tigen Ollama, OpenAI oder Anthropic.

---

### ![macOS](https://img.shields.io/badge/-macOS-000000?logo=apple&logoColor=white) Installation

**Voraussetzungen:** macOS 10.15+ Â· 10 GB freier Speicher

**Download:** [GitHub Releases][releases] â€“ Universal DMG (~1.3 GB) | Apple Silicon DMG (~1.2 GB)

#### 1ï¸âƒ£ HablarÃ¡ installieren
- DMG Ã¶ffnen â†’ `HablarÃ¡.app` in `Programme` ziehen
- Sicherheitseinstellungen: "Trotzdem Ã¶ffnen" (einmalig)

<details>
<summary>ğŸ“‹ Alternative: via Homebrew</summary>

```bash
brew install --cask fidpa/hablara/hablara
```

Updates: `brew upgrade --cask hablara`

</details>

#### 2ï¸âƒ£ Ollama + Sprachmodell installieren (empfohlen)

```bash
curl -fsSL https://raw.githubusercontent.com/fidpa/hablara/main/scripts/setup-ollama-mac.sh | bash
```

<details>
<summary>ğŸ“‹ Was macht dieser Befehl?</summary>

1. Installiert Ollama (falls nicht vorhanden)
2. LÃ¤dt qwen2.5:7b Modell (~4.7 GB)
3. Erstellt optimiertes Custom-Modell
4. Verifiziert Installation

</details>

---

### ![Linux](https://img.shields.io/badge/-Linux-FCC624?logo=linux&logoColor=black) Installation

**Voraussetzungen:** Ubuntu 20.04+ / Debian 11+ / Fedora 36+ Â· x64 Â· 10 GB freier Speicher

**Download:** [GitHub Releases][releases] â€“ .deb (Debian/Ubuntu) | .rpm (Fedora/RHEL) | .AppImage (Universal)

#### 1ï¸âƒ£ HablarÃ¡ installieren
- Paket herunterladen (.deb, .rpm oder .AppImage)
- Mit Paketmanager installieren oder AppImage direkt ausfÃ¼hren

<details>
<summary>ğŸ“‹ Installations-Befehle nach Distribution</summary>

**Debian/Ubuntu (.deb):**
```bash
sudo dpkg -i hablara_1.1.1_amd64.deb
sudo apt-get install -f  # Falls AbhÃ¤ngigkeiten fehlen
```

**Fedora/RHEL (.rpm):**
```bash
sudo rpm -i hablara-1.1.1-1.x86_64.rpm
# oder: sudo dnf install hablara-1.1.1-1.x86_64.rpm
```

**AppImage (Universal, keine Installation nÃ¶tig):**
```bash
chmod +x hablara_1.1.1_amd64.AppImage
./hablara_1.1.1_amd64.AppImage
```

AppImages kÃ¶nnen mit [AppImageLauncher](https://github.com/TheAssassin/AppImageLauncher) ins AnwendungsmenÃ¼ integriert werden.

</details>

#### 2ï¸âƒ£ Ollama + Sprachmodell installieren (empfohlen)

```bash
curl -fsSL https://raw.githubusercontent.com/fidpa/hablara/main/scripts/setup-ollama-linux.sh | bash
```

<details>
<summary>ğŸ“‹ Was macht dieser Befehl?</summary>

1. Installiert Ollama (falls nicht vorhanden)
2. LÃ¤dt qwen2.5:7b Modell (~4.7 GB)
3. Erstellt optimiertes Custom-Modell
4. Verifiziert Installation

</details>

#### 3ï¸âƒ£ API Key Speicherung (OpenAI/Anthropic)

**Cloud-Provider (OpenAI/Anthropic) benÃ¶tigen einen SchlÃ¼sselbund-Dienst:**

<details>
<summary>ğŸ“‹ BenÃ¶tigte Pakete nach Desktop-Umgebung</summary>

**GNOME (Standard bei Ubuntu, Fedora, Debian):**
```bash
# Meist bereits installiert
sudo apt install gnome-keyring  # Debian/Ubuntu
sudo dnf install gnome-keyring  # Fedora/RHEL
```

**KDE Plasma 6 (2024+):**
```bash
sudo apt install kwalletmanager  # Debian/Ubuntu
sudo dnf install kwalletmanager  # Fedora/RHEL
# Plasma 6 nutzt ksecretd (Secret Service native, voll kompatibel)
```

**KDE Plasma 5 (Ã¤lter):**
```bash
sudo apt install kwalletmanager  # Debian/Ubuntu
sudo dnf install kwalletmanager  # Fedora/RHEL
# Plasma 5 benÃ¶tigt Secret Service Bridge-Aktivierung in KWallet-Einstellungen
```

**Minimal Window Managers (i3, bspwm, etc.):**
```bash
# Manuelle Installation von GNOME Keyring (auch ohne GNOME Desktop)
sudo apt install gnome-keyring libsecret-1-0  # Debian/Ubuntu
sudo dnf install gnome-keyring libsecret      # Fedora/RHEL

# Daemon manuell starten (falls nicht automatisch):
eval $(gnome-keyring-daemon --start --components=secrets)
```

**KeePassXC (Alternative fÃ¼r alle Desktop-Umgebungen):**
```bash
sudo apt install keepassxc  # Debian/Ubuntu
sudo dnf install keepassxc  # Fedora/RHEL
# KeePassXC â†’ Einstellungen â†’ Secret Service Integration aktivieren
```

</details>

**âš ï¸ Hinweis fÃ¼r Flatpak/Snap:**
- Direct Distribution: .deb/.rpm/.AppImage funktionieren Out-of-the-Box
- Flatpak/Snap: API Keys kÃ¶nnen in v1.0.x NICHT sicher gespeichert werden (XDG Portal Secret API fehlt)
- **Workaround:** Ollama (lokal) nutzen oder auf Direct Distribution umsteigen

**Troubleshooting:**
- Fehler "Kein SchlÃ¼sselbund-Dienst gefunden" â†’ Paket installieren (siehe oben)
- Fehler "SchlÃ¼sselbund antwortet nicht" â†’ Daemon starten: `gnome-keyring-daemon --start`
- KDE: Secret Service in KWallet aktivieren: `systemsettings5` â†’ Wallet â†’ "Enable Secret Service"

---

### ![Windows](https://img.shields.io/badge/-Windows-0078D6?logo=windows&logoColor=white) Installation

**Voraussetzungen:** Windows 10/11 (x64) Â· 10 GB freier Speicher

**Download:** [GitHub Releases][releases] â€“ NSIS Installer (~1.1 GB, empfohlen) | MSI (~1.2 GB)

#### 1ï¸âƒ£ HablarÃ¡ installieren
- `.exe` oder `.msi` herunterladen und ausfÃ¼hren
- Windows Defender SmartScreen: "Weitere Informationen" â†’ "Trotzdem ausfÃ¼hren"
  _(App ist nicht signiert)_

#### 2ï¸âƒ£ Ollama + Sprachmodell installieren (empfohlen)

**Einmalige Vorbereitung:**
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

**Setup-Skript ausfÃ¼hren:**
```powershell
Invoke-WebRequest -Uri "https://raw.githubusercontent.com/fidpa/hablara/main/scripts/setup-ollama-win.ps1" -OutFile "$env:TEMP\setup-ollama-win.ps1"; & "$env:TEMP\setup-ollama-win.ps1"
```

<details>
<summary>ğŸ“‹ Was macht dieser Befehl?</summary>

1. Installiert Ollama via winget (falls nicht vorhanden)
2. LÃ¤dt qwen2.5:7b Modell (~4.7 GB)
3. Erstellt optimiertes Custom-Modell
4. Verifiziert Installation

</details>

---

<details>
<summary>Alternative: Cloud-LLM (OpenAI/Anthropic)</summary>

1. **HablarÃ¡ Ã¶ffnen** â†’ Einstellungen (Zahnrad-Icon) â†’ KI-Modelle
2. **Anbieter wÃ¤hlen**: OpenAI oder Anthropic
3. **API Key eingeben**:
   - OpenAI: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
   - Anthropic: [console.anthropic.com/settings/keys](https://console.anthropic.com/settings/keys)

Cloud-LLM erfordert DSGVO-Einwilligung (wird beim ersten Start abgefragt)

</details>

---

## Funktionen

- **Hotkey-Aktivierung** â€“ Starte die Aufnahme mit Ctrl+Shift+D aus jeder Anwendung
- **Native Audio-Aufnahme** â€“ Professionelle AudioqualitÃ¤t fÃ¼r prÃ¤zise Transkription (cpal @ 16kHz)
- **Lokale Transkription** â€“ Audio-Daten bleiben auf dem GerÃ¤t
- **LED-Pegelanzeige** â€“ 10-Segment Visualisierung wÃ¤hrend der Aufnahme (6 grÃ¼n/2 orange/2 rot)

**AI-Enrichment (7 psychologisch-fundierte Analysen):**

| Analyse | Framework | Output |
|---------|-----------|--------|
| **Emotionserkennung** | Plutchik, Russell | 10 Emotionstypen, Dual-Track (Audio 40% + Text 60%) |
| **Argumentationsfehler** | CEG-Prompting | 16 Fehlschluss-Typen erkennen |
| **GFK-Analyse** | Rosenberg | Beobachtungen, GefÃ¼hle, BedÃ¼rfnisse, Bitten |
| **Kognitive Verzerrungen** | Beck (CBT) | 7 Denkmuster + Reframe-VorschlÃ¤ge |
| **Vier-Seiten-Modell** | Schulz von Thun | Sachinhalt, Selbstoffenbarung, Beziehung, Appell |
| **TonalitÃ¤t** | Sprechweise-Analyse | Formell/Informell, Bestimmt/ZurÃ¼ckhaltend |
| **Topic-Klassifizierung** | 7 Kategorien | Arbeit, Gesundheit, Beziehungen, etc. |

- **RAG-Wissensassistent** â€“ Beantwortet zuverlÃ¤ssig Fragen (Kontext Ã¼ber letzte 3 Nachrichten per React State). Intelligente AbkÃ¼rzungserkennung fÃ¼r psychologische Fachbegriffe (GFK, CBT, VAD)


<details>
<summary><b>Psychologische Frameworks im Detail</b></summary>

**GFK (Gewaltfreie Kommunikation â€“ Marshall Rosenberg):**
- 6 Bereiche: Beobachtungen, GefÃ¼hle, BedÃ¼rfnisse, Bitten, GFK-Ãœbersetzung, Reflexionsfrage
- Ziel: Kommunikations-Awareness, BedÃ¼rfnis-Erkennung

**Kognitive Verzerrungen (CBT â€“ Aaron Beck):**
- 7 Typen: Katastrophisieren, Schwarz-WeiÃŸ-Denken, Ãœbergeneralisierung, Gedankenlesen, Personalisierung, Emotionales Schlussfolgern, Sollte-Aussagen
- Output: Thinking Style Badge (Ausgewogen/Leicht verzerrt/Stark verzerrt) + Reframe-VorschlÃ¤ge

**Vier-Seiten-Modell (Schulz von Thun):**
- 4 Quadranten: Sachinhalt (blau), Selbstoffenbarung (lila), Beziehung (pink), Appell (orange)
- Output: Potenzielle MissverstÃ¤ndnisse + Kommunikations-Tipps

**Wichtig:** Alle Features dienen der **Selbstreflexion**, nicht der klinischen Diagnostik. KI-Accuracy-Disclaimer (EU AI Act Art. 52) in Tour und About-Section. Krisenhotline: Telefonseelsorge 0800 111 0 111 (24/7, kostenlos).

</details>

**Technisch:**
- **Flexible LLM-Wahl** â€“ Ollama (lokal/kostenlos), OpenAI, oder Anthropic Claude
- **Persistente Speicherung** â€“ Alle Aufnahmen mit Metadaten automatisch gespeichert
- **Chat-Export** â€“ 5 Formate (Markdown/TXT/PDF/HTML/DOCX) mit Export aller Metadaten
- **PDF Export** â€“ Einzelne Aufnahmen als PDF exportieren (10 Sektionen: Transkript + alle Analysen)
- **Sichere API Key Speicherung** â€“ OS-native VerschlÃ¼sselung (Keychain/Credential Manager/Secret Service)
- **Bundle-Size-Optimierung** â€“ INT8-Quantization (-75% Model Size)
- **Window State Persistence** â€“ Position und GrÃ¶ÃŸe werden automatisch gespeichert
- **Robustheit** â€“ 4 Error Boundaries isolieren Fehler auf Komponentenebene (Chat-Crash â‰  App-Crash)

<details>
<summary><b>Beispiel-Workflow</b> â€“ Demo einer typischen Analyse</summary>

**Beispiel 1:**
```text
"Das GesprÃ¤ch mit Lisa hat mir gut getan.
Sie hat einen Punkt angesprochen, den ich so nicht gesehen hatte.
Ich werde das morgen anders angehen."
```

| Analyse | Ergebnis |
|---------|----------|
| **Emotion** | Ruhe (78% Confidence) â€“ Stabile Stimmlage, moderate Speech Rate |
| **GFK** | BedÃ¼rfnis nach VerstÃ¤ndnis und Verbindung erkannt |
| **Selbstreflexion** | Offenheit fÃ¼r neue Perspektiven, konstruktive Haltung |

**Beispiel 2:**
```text
"Nach dem Spaziergang bin ich viel klarer.
Die frische Luft hat geholfen, die Gedanken zu sortieren.
Jetzt weiÃŸ ich, wie ich das angehen will."
```

| Analyse | Ergebnis |
|---------|----------|
| **Emotion** | Klarheit/Zuversicht (82% Confidence) â€“ Ruhiger Tonfall |
| **Vier-Seiten** | Selbstoffenbarung: Reflexion Ã¼ber eigene Strategien |
| **Selbstreflexion** | Erkenntnis Ã¼ber wirksame BewÃ¤ltigungsmethoden |

</details>

**Hinweise:**
- **Verarbeitungsdauer** hÃ¤ngt ab von: AufnahmelÃ¤nge, Analyseebenen, Hardware, LLM-Anbieter
- **KI-Ergebnisse** dienen der Selbstreflexion und kÃ¶nnen fehlerhaft sein

---

<details>
<summary><b>Technische Details</b> â€“ Emotionserkennung, Security, Implementierung</summary>

### Emotionserkennung

**Dual-Track Emotions-Erkennung**:
- **Audio-Track (40%)**: 12 Features (Prosodisch + Spektral)
  - 3 Basis: TonhÃ¶he, Energie, Sprechrate
  - 5 Prosodisch: TonhÃ¶he-Varianz/-Bereich, Energie-Varianz, Pausendauer/-hÃ¤ufigkeit
  - 4 Spektral: ZCR, Spectral Centroid/Rolloff/Flux
- **Text-Track (60%)**: LLM-Semantik (Ollama/OpenAI/Anthropic)
- **Fusion**: Gewichteter Durchschnitt + 15% Confidence-Boost bei Ãœbereinstimmung

**Methodik**: Dual-Track Fusion (Audio 40% + Text 60%, Poria et al. 2017) mit Confidence-Boosting

**Differenzierung**:
- Stress vs. Aufregung: TonhÃ¶he-Varianz (unstetig vs. stetig)
- Aggression vs. Ãœberzeugung: Spectral Flux (abrupt vs. flieÃŸend)

**Wissenschaftliche Quellen**: Plutchik (1980), Russell (1980), PAD Model, IEMOCAP Dataset

### Implementierung

**Performance**:
- **Audio-Analyse**: Rust-native (12 Features)
- **LLM Enrichment**: Parallel-Processing fÃ¼r minimale Latenz
- **Bundle Size**: 2 ONNX-Modelle (VAD 1.8 MB + Embedding 118 MB), Embedding INT8-quantisiert (-75%)

**Robustheit**:
- **spawn_blocking Pattern**: Non-blocking I/O fÃ¼r Storage (verhindert 500-Errors)
- **Memory Leak Prevention**: Named EventListeners + Cleanup (AudioPlayer gefixt)
- **ML Engineering**: Self-quantized ONNX model (FP32â†’INT8, 75% Reduktion, <2% Accuracy-Loss)
- **Safety Guardrails**: 7-Pattern LLM Output Filter (Defense-in-Depth) verhindert klinische Aussagen (ICD-10, Dosierungen). Keine Diagnosen, Arztvorbehalt gewahrt

**Code-QualitÃ¤t**:
- TypeScript strict mode, Rust mit serde
- <400 Zeilen pro Datei (SOLID, SRP)
- Immutability-Patterns (kein `obj.prop = value`)

### TastenkÃ¼rzel & Accessibility

- `Ctrl+Shift+D` â€“ Aufnahme starten/stoppen (global)
- `Tab` / `Shift+Tab` â€“ Navigation
- `Ctrl+Enter` â€“ Text absenden
- WCAG 2.1 AA konform, Screen-Reader-kompatibel

</details>

<details>
<summary><b>Design-Entscheidungen</b> â€“ Warum Tauri, Native Audio, Ollama?</summary>

*Architektur-Diagramm: Siehe [Architektur](#architektur) unten.*

#### Architektur

**Warum Tauri 2.0 statt Electron?**
- Native Rust-Integration fÃ¼r lokale ML-Modelle (whisper.cpp, ONNX) ohne FFI-Overhead
- Geringerer RAM-Verbrauch â€“ wichtig bei parallelem Ollama + Whisper + Embedding
- Schnellerer Startup (~200ms vs. ~800ms), integrierte Security-Sandbox

**Warum Native Audio (cpal) statt Web Audio API?**
- Browser ignoriert 16kHz Request (liefert 48kHz). VAD: 0% vs. >90% mit cpal
- FFT-Resampling (rubato) garantiert Whisper-kompatible Sample-Rate

**Warum Next.js 14 + React 18 pinned (nicht 15/19)?**
- Tauri 2.0 KompatibilitÃ¤t â€“ neuere Versionen brechen Build
- Bewusste StabilitÃ¤t vor "Bleeding Edge"

#### AI/ML Pipeline

**Warum Silero VAD vor Whisper?**
- Whisper halluziniert bei Stille ("Danke fÃ¼rs Zuschauen!", Musik-Notationen)
- VAD filtert Nicht-Sprache vor Transkription â†’ 0% False Positives
- 1.8 MB ONNX, <1ms Latenz, threshold-basiert (0.3)

**Warum whisper.cpp (lokal) statt Cloud-STT?**
- 100% Privacy, kostenlos, schnelle lokale Inferenz

**Warum Dual-Track Emotion (Audio 40% + Text 60%)?**
- Single-Track limitiert (nur Audio ODER Text), Dual-Track Fusion deutlich robuster
- Audio erkennt Sarkasmus (Prosody), Text erkennt Semantik

**Warum 12 Audio Features statt 3?**
- Erweitert von 3 auf 12 Features (inkl. Prosodic/Spectral)
- Differenziert: Stress/Aufregung (TonhÃ¶he-Varianz), Aggression/Ãœberzeugung (Spectral Flux)

**Warum Ollama als Standard-LLM?**
- Privacy-First, kostenlos, 2-Command Setup, Persistent RAM (kein Cold-Start)

**Warum Qwen 2.5 als Modell?**
- **Mehrsprachig trainiert:** Inkl. Deutsch
- **Balanced Size:** 7B Parameter bietet einen guten Kompromiss zwischen QualitÃ¤t und Latenz
- **JSON Compliance:** ZuverlÃ¤ssige strukturierte Outputs fÃ¼r unsere Prompt-Architektur
- **Angepasstes Modelfile:** Reduzierter Context (8K statt 32K) fÃ¼r beschleunigte Inferenz, Temperature 0.3 fÃ¼r konsistente Outputs

**Warum Multi-Anbieter LLM?**
- Wahlfreiheit: Privacy (Ollama) vs. Geschwindigkeit (OpenAI) vs. QualitÃ¤t (Anthropic), kein Vendor Lock-in

**Warum RAG-Chatbot (78 Chunks)?**
- Ohne RAG halluziniert das LLM â€“ mit RAG: hohe ZuverlÃ¤ssigkeit
- Kontextbasierte Antworten reduzieren Halluzinationen deutlich

**Warum INT8-quantisiertes Embedding (118 MB statt 448 MB)?**
- 74.9% GrÃ¶ÃŸenreduktion bei <2% Accuracy-Verlust (0.990 similarity)
- Self-quantized fÃ¼r Bundle-Optimierung

#### Security & Privacy

**Warum Keychain / Credential Manager / Secret Service statt localStorage?**
- localStorage: XSS-anfÃ¤llig, Klartext auf Disk
- OS-native: AES-256-GCM (macOS Keychain), DPAPI (Windows), D-Bus Secret Service (Linux), Zero Plaintext

**Warum DSGVO Art. 6 statt Art. 9?**
- Art. 9 erfordert DPIA + MDR-Zertifizierung (~50.000 EUR) â€“ unverhÃ¤ltnismÃ¤ÃŸig fÃ¼r Selbstreflexions-Tool

**Warum KI-Accuracy-Disclaimer (EU AI Act Art. 52)?**
- Transparenzpflicht: "KI-Ergebnisse kÃ¶nnen fehlerhaft sein"
- 4-Stufen-Strategie: Tour, About-Section, Confidence-Tooltips, Krisenhotline

#### UX-Entscheidungen

**Warum 4 Error Boundaries statt globaler Fehlerbehandlung?**
- Komponenten-Isolation: Chat-Crash â‰  App-Crash
- "Fail Small, Recover Fast" â€“ nur betroffene Komponente zeigt Fehler

</details>

<details>
<summary><b>Entwicklungsumgebung</b> â€“ Voraussetzungen, Installation, Build</summary>

### Voraussetzungen

- **Node.js** >= 18
- **Rust** >= 1.70
- **pnpm** (oder npm)
- **Ollama** (optional, fÃ¼r lokales LLM)
- **Git LFS** (erforderlich fÃ¼r ONNX-Modelle)

### 1. Repository clonen mit Git LFS

**Wichtig:** HablarÃ¡ nutzt Git LFS fÃ¼r groÃŸe Modelle (Whisper 1.6 GB + Embedding 118 MB).

```bash
# Git LFS installieren (einmalig)
# macOS:
brew install git-lfs

# Windows:
winget install Git.LFS
# oder: https://git-lfs.com â†’ Installer

git lfs install

# Repository clonen (LFS-Dateien werden automatisch heruntergeladen)
git clone https://github.com/fidpa/hablara.git
cd hablara

# Verifizieren: Embedding-Modell sollte ~118 MB groÃŸ sein
# macOS/Linux:
ls -lh public/models/onnx-models/paraphrase-multilingual-MiniLM-L12-v2-onnx/onnx/model_quantized.onnx
# Windows (PowerShell):
# Get-Item public\models\onnx-models\paraphrase-multilingual-MiniLM-L12-v2-onnx\onnx\model_quantized.onnx | Select-Object Length
```

**Ohne Git LFS:** RAG-Feature (Chatbot) funktioniert nicht (kein Embedding-Modell verfÃ¼gbar).

**Troubleshooting:** Falls das Modell nur wenige KB groÃŸ ist (LFS-Pointer statt BinÃ¤rdatei):
```bash
git lfs pull  # LFS-Dateien manuell herunterladen
```

### 2. Dependencies installieren

```bash
pnpm install
```

### 3. Whisper Model herunterladen (optional)

```bash
# Erstelle Verzeichnisse
# macOS/Linux:
mkdir -p src-tauri/binaries src-tauri/models
# Windows (PowerShell):
# New-Item -ItemType Directory -Force -Path src-tauri\binaries, src-tauri\models

# whisper.cpp binary kompilieren (oder herunterladen)
# Siehe: https://github.com/ggerganov/whisper.cpp

# Model herunterladen (german-turbo empfohlen)
# macOS/Linux:
curl -L -o src-tauri/models/ggml-model.bin \
  https://huggingface.co/cstr/whisper-large-v3-turbo-german-ggml/resolve/main/ggml-model.bin
# Windows (PowerShell):
# Invoke-WebRequest -Uri "https://huggingface.co/cstr/whisper-large-v3-turbo-german-ggml/resolve/main/ggml-model.bin" -OutFile "src-tauri\models\ggml-model.bin"
```

### 4. Ollama einrichten (empfohlen fÃ¼r lokale KI)

**Ollama ist der empfohlene LLM-Anbieter** fÃ¼r optimale Performance (persistent server).

**Bereits installiert?** PrÃ¼fen mit:
```bash
ollama --version  # Falls installiert: Springe zu Schritt 2
```

**Schritt 1: Ollama installieren**

```bash
# macOS: brew install ollama
# Windows: winget install Ollama.Ollama
# Oder: https://ollama.ai/download
```

**Schritt 2: Basis-Modell herunterladen** (4.7 GB, einmalig)
```bash
ollama pull qwen2.5:7b
```

**Schritt 3: HablarÃ¡-optimiertes Modell erstellen**
```bash
ollama create qwen2.5:7b-custom -f scripts/ollama/qwen2.5-7b-custom.modelfile
```

**LLM-Anbieter Alternativen:**
- **MLX-LLM** (Optional, Power-User): 3x schneller, manuelles Setup erforderlich
- **OpenAI/Anthropic API**: API Key in Einstellungen konfigurieren

### 5. Development starten

```bash
pnpm run dev:safe
```

### Build

```bash
# App erstellen (alle Plattformen)
pnpm tauri build
```

| Plattform | Output |
|-----------|--------|
| macOS | `src-tauri/target/release/bundle/dmg/` |
| Windows | `src-tauri/target/release/bundle/nsis/` und `msi/` |
| Linux | `src-tauri/target/release/bundle/deb/`, `rpm/` und `appimage/` |

</details>

<details>
<summary><b>LLM-Anbieter</b> â€“ Ollama, OpenAI, Anthropic</summary>

HablarÃ¡ unterstÃ¼tzt drei LLM-Anbieter:

| Anbieter | Vorteile | Setup-Aufwand | Kosten | DSGVO | Empfehlung |
|----------|----------|---------------|--------|-------|------------|
| **Ollama** | 100% lokal, keine API-Keys | Niedrig | Kostenlos | Konform | **Standard** |
| **OpenAI** | Schnellste Antworten, GPT-4o | Sehr niedrig | Pay-per-Use | Cloud | Bei Bedarf |
| **Anthropic** | Claude Sonnet, thoughtful | Sehr niedrig | Pay-per-Use | Cloud | Bei Bedarf |

</details>

<details>
<summary><b>FAQ</b> â€“ HÃ¤ufige Fragen</summary>

### Kann ich es ohne Ollama testen?
**Ja**, mit OpenAI/Anthropic API-Key (Cloud-basiert).

### Funktioniert es auf Windows/Linux?
**Windows:** Ja, vollstÃ¤ndig unterstÃ¼tzt (x64, whisper.cpp CPU). Download im [GitHub Releases][releases].
**Linux:** Ja, vollstÃ¤ndig unterstÃ¼tzt (x64, Ubuntu 20.04+). Download: .deb, .rpm oder .AppImage im [GitHub Releases][releases].

### Wie groÃŸ ist das Ollama-Model?
**~4.7 GB** (qwen2.5:7b). LeistungsstÃ¤rkere Alternative: qwen2.5:14b (~9 GB).

### Wo speichert HablarÃ¡ Daten?

**macOS:**
```
~/Library/Application Support/Hablara/recordings/
```

**Linux:**
```
~/.local/share/hablara/recordings/
```
(XDG_DATA_HOME Standard)

**Windows:**
```
%LOCALAPPDATA%\Hablara\recordings\
```

**Migration:** Ab v1.0.4 werden alte Aufnahmen aus `~/Hablara/recordings/` automatisch an die neuen Speicherorte migriert.

**Details:** Siehe [STORAGE.md](docs/guides/STORAGE.md)

### Was ist der Unterschied zwischen App Store und Direct Distribution?

| Feature | Direct (GitHub) | App Store |
|---------|-----------------|-----------|
| **Hotkey** | âœ… `Ctrl+Shift+D` | âŒ Nicht verfÃ¼gbar |
| **Ollama Setup** | Terminal-Befehl | App oder Cloud-API |
| **Speicherort** | `Application Support/` | `Documents/` |
| **Updates** | Manuell | Automatisch |

**Empfehlung:** Direct Distribution fÃ¼r volle Feature-UnterstÃ¼tzung (Global Hotkeys).

### Kann ich alte Aufnahmen ansehen und deren Analysen exportieren?
**Ja** â€“ Folder-Icon in der Kopfzeile â†’ Aufnahmen-Verzeichnis Ã¶ffnet sich.

### Kann ich den Chat-Verlauf exportieren?
**Ja** â€“ 5 Export-Formate verfÃ¼gbar:
- **Markdown (.md)** â€“ YAML Frontmatter + Full Metadata (GFK, Cognitive, FourSides)
- **Plain Text (.txt)** â€“ ASCII Art Separators, simplified Metadata
- **PDF** â€“ Via jsPDF, Print-optimized Styling
- **HTML** â€“ Fallback fÃ¼r Popup-Blocker
- **Word (.docx)** â€“ Rich Formatting mit Farben, professionelle Dokumente

**Export-Button** in der Chat-Ansicht (neben RAG-Chatbot). Alle Metadaten (Emotion, Fallacies, Audio Features) werden inkludiert, wenn aktiviert.

### Wie kann ich zwischen LLM-Anbietern wechseln?
**Einstellungen â†’ KI-Modelle** â€“ Ollama/OpenAI/Anthropic mit einem Klick wÃ¤hlbar.

</details>

---

## Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HablarÃ¡ Desktop App                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Frontend (Next.js 14 + React 18)                         â”‚  â”‚
â”‚  â”‚  â€¢ UI Components (Audio Recorder, Emotion Indicator)      â”‚  â”‚
â”‚  â”‚  â€¢ State Management (React Hooks)                         â”‚  â”‚
â”‚  â”‚  â€¢ Hotkey Listener (Ctrl+Shift+D)                         â”‚  â”‚
â”‚  â”‚  â€¢ RAG (ONNX 118 MB + SQLite FTS5)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚ IPC (Tauri Commands)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Rust Backend (Tauri 2.0)                                 â”‚  â”‚
â”‚  â”‚  â€¢ Native Audio (cpal @ 16kHz)                            â”‚  â”‚
â”‚  â”‚  â€¢ Silero VAD (ONNX, 1.8 MB)                              â”‚  â”‚
â”‚  â”‚  â€¢ Audio Analysis (12 Features)                           â”‚  â”‚
â”‚  â”‚  â€¢ Storage Manager (JSON Dateien)                         â”‚  â”‚
â”‚  â”‚  â€¢ whisper.cpp Integration (Sidecar)                      â”‚  â”‚
â”‚  â”‚  â€¢ API Key Security (native Keystores)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Verarbeitungs-Pipeline

```
Aufnahme â†’ VAD â†’ whisper.cpp â†’ LLM-Analyse â†’ Speicherung â†’ UI
   â”‚        â”‚         â”‚             â”‚             â”‚          â”‚
   â–¼        â–¼         â–¼             â–¼             â–¼          â–¼
Hotkey   Silero    Transkription  Dual-Track   Auto-Save   Ergebnis
(Ctrl+   filtert   (lokal)        Emotion +    (lokal)     anzeigen
Shift+D) Stille                   Fehlschluss
                                  (parallel)
```

### KI-Modelle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Audio-Pipeline                     RAG-Wissensassistent       â”‚
â”‚                                                                 â”‚
â”‚   Audio-Eingang                      User-Frage                 â”‚
â”‚        â”‚                                  â”‚                     â”‚
â”‚        â–¼                                  â–¼                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ Silero VAD (1.8 MB)â”‚            â”‚ Embedding (118 MB) â”‚      â”‚
â”‚   â”‚ filtert Stille     â”‚            â”‚ Semantische Suche  â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚        â”‚                                  â”‚                     â”‚
â”‚        â–¼                                  â–¼                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ whisper.cpp (1.6GB)â”‚            â”‚ SQLite FTS5        â”‚      â”‚
â”‚   â”‚ Speech-to-Text     â”‚            â”‚ 78 Wissens-Chunks  â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚        â”‚                                  â”‚                     â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                        â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ LLMs (Multi-Provider, frei wÃ¤hlbar via Einstellungen)    â”‚  â”‚
â”‚   â”‚ â€¢ Ollama (lokal, 2-4s, gratis, Datenschutz)              â”‚  â”‚
â”‚   â”‚ â€¢ OpenAI (Cloud, 0.5-2s, gÃ¼nstig, Geschwindigkeit)       â”‚  â”‚
â”‚   â”‚ â€¢ Anthropic (Cloud, 0.5-2s, teurer, QualitÃ¤t)            â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚                                  â”‚                     â”‚
â”‚        â–¼                                  â–¼                     â”‚
â”‚   7 Analysen                         Chat-Antwort               â”‚
â”‚   (Emotion, GFK, etc.)               (kontextbasiert)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech-Stack (3-Tier Architektur)

| Layer | Technologie | Zweck |
|-------|-------------|-------|
| **Frontend** | Next.js 14, React 18, TailwindCSS | UI, State Management |
| **Desktop** | Tauri 2.0, Rust 1.70+ | Native Audio, IPC, Storage |
| **AI/ML** | whisper.cpp (german-turbo), Ollama (qwen2.5:7b) | STT, LLM Enrichment |
| **VAD** | Silero VAD v4 (ONNX, 1.8 MB) | Voice Activity Detection |
| **Embedding** | paraphrase-multilingual-MiniLM-L12-v2 (ONNX INT8, 118 MB) | RAG Semantic Search |
| **Security** | keyring-rs (OS-native Keychain) | API Key VerschlÃ¼sselung |

---

## Datenschutz

**100% lokale Verarbeitung mÃ¶glich** â€“ Keine Cloud-Pflicht, volle Datenkontrolle.

Weitere Informationen: [DatenschutzerklÃ¤rung](https://www.hablara.de/datenschutz/)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    100% Lokale Option                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚    Audio    â”‚-->â”‚ whisper.cpp â”‚-->â”‚   Ollama    â”‚     â”‚
â”‚   â”‚    (cpal)   â”‚   â”‚   (lokal)   â”‚   â”‚   (lokal)   â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          |                                   |            â”‚
â”‚          v                                   v            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚  Speicher   â”‚<--------------------â”‚   Analyse   â”‚     â”‚
â”‚   â”‚   (lokal)   â”‚                     â”‚  Ergebnis   â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DSGVO-Compliance

| Aspekt | Details |
|--------|---------|
| **Rechtliche Basis** | DSGVO Art. 6(1)(a) â€“ Einwilligung |
| **Datenklassifizierung** | Nicht-sensible personenbezogene Daten |
| **Zweckbindung** | Audio ausschlieÃŸlich fÃ¼r Transkription & Sprachanalyse |
| **Speicherort** | Plattformspezifisch (siehe [STORAGE.md](docs/guides/STORAGE.md)) |
| **Cloud-Option** | Nur mit expliziter Einwilligung (OpenAI/Anthropic) |
| **Auto-Cleanup** | Konfigurierbar (Standard: 25-500 Aufnahmen) |

### Technische MaÃŸnahmen

| MaÃŸnahme | Implementierung |
|----------|-----------------|
| **API Key VerschlÃ¼sselung** | macOS Keychain (AES-256-GCM) / Windows Credential Manager (DPAPI) / Linux Secret Service (D-Bus) |
| **Keine Cloud-Pflicht** | whisper.cpp + Ollama vollstÃ¤ndig offline |
| **DatenlÃ¶schung** | "Alle lÃ¶schen"-Button, konfigurierbare Aufbewahrung |
| **Open-Source** | Transparenz durch offenen Code |

### Sicherheitsarchitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Sicherheitsarchitektur                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  Input:   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚           â”‚ User Input â”‚->â”‚  Zod   â”‚->â”‚ XSS-Filter â”‚      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                           â”‚
â”‚  Output:  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚           â”‚ LLM Output â”‚->â”‚ SafetyFilter â”‚-> Display      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                           â”‚
â”‚  Storage: â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚           â”‚ Lokal: Plattformspezifische Pfade       â”‚     â”‚
â”‚           â”‚ API Keys: Keychain/Credential/Secret    â”‚     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Keine Cloud-Datenbank** â€“ Keine Remote-AngriffsflÃ¤che, alle Daten lokal
- **VerschlÃ¼sselte Credentials** â€“ API Keys nur in OS-native Keystores (Keychain/Credential Manager/Secret Service), niemals Klartext
- **Input Validation** â€“ Alle User-Eingaben via Zod Schema validiert
- **XSS Protection** â€“ LLM-Output wird vor Rendering sanitized
- **Safety Filter** â€“ Blockiert problematische LLM-Outputs
- **App Sandbox** â€“ macOS Hardened Runtime / Windows Security Features begrenzen Systemzugriff

### Abgrenzung zu Gesundheits-Apps

HablarÃ¡ dient der **Selbstreflexion** und ist kein medizinisches Produkt:

- **Art. 6 (Einwilligung):** Emotion-Tracking = Self-Awareness, keine klinische Diagnostik
- **Abgrenzung:** Anders als MindDoc (klinisch, Art. 9) oder Daylio (nur Mood-Logging)

**Wichtiger Hinweis:** Bei Verwendung von Cloud-Anbietern (OpenAI, Anthropic) gelten deren Datenschutzbestimmungen.

---

## Vergleich

| Funktion | HablarÃ¡ | Otter.ai | Fireflies.ai | Whisper (plain) |
|---------|---------|----------|--------------|-----------------|
| **Datenschutz (Offline)** | Ja (100%) | Nein | Nein | Ja |
| **Emotions-Erkennung** | Ja (12 Features) | Nein | Ja (3-Tier Sentiment)* | Nein |
| **Fehlschluss-Erkennung** | Ja (16 Typen) | Nein | Nein | Nein |
| **Selbstreflexion** | Ja | Nein | Nein | Nein |
| **Psychol. Frameworks** | Ja (7) | Nein | Nein | Nein |
| **Meeting-Features** | Nein | Ja | Ja | Nein |
| **Preis** | Open-Source | $16.99/mo | $10/mo (annual)* | Kostenlos |

\*Fireflies bietet Sentiment-Analyse (positiv/negativ/neutral) ab Business-Plan â€” keine granulare Emotion-Detection wie HablarÃ¡ (10 Emotionstypen, Dual-Track Audio+Text).
\*Fireflies Pro: $18/mo (monthly) / $10/mo (annual). Otter.ai Pro: $16.99/mo (monthly) / $8.33/mo (annual).

---

## Mitwirken

BeitrÃ¤ge sind willkommen! Siehe [GitHub Issues][issues] fÃ¼r offene Aufgaben.

- Bug-Reports und Feature-Requests via Issues
- Pull Requests gerne gegen `main` Branch

---

## Lizenz

MIT License â€“ siehe [LICENSE](LICENSE) fÃ¼r Details.

---

**Autor:** Marc Allgeier | **Version:** 1.1.1

---

<!-- Link-Definitionen -->
[releases]: https://github.com/fidpa/hablara/releases
[issues]: https://github.com/fidpa/hablara/issues

import type { KnowledgeChunk } from "../../types";

/**
 * General knowledge chunks (23 chunks)
 *
 * Meta information about Hablará:
 * - App overview and features
 * - Dual-Track Emotion Analysis and Audio Features
 * - LLM Providers (Ollama, OpenAI, Anthropic)
 * - Getting started, onboarding, GDPR
 * - Troubleshooting guides
 * - Analysis features overview (NEW)
 *
 * @see {@link ../../types.ts} for KnowledgeChunk interface
 */
export const generalChunks: KnowledgeChunk[] = [
  {
    id: "general_what_is_hablara",
    category: "general",
    title: "Was ist Hablará?",
    content:
      "Hablará ist eine Desktop-App für Selbstreflexion mit Voice-Analyse. Features: Emotion Detection (10 Typen), Fallacy Detection (16 Typen), Tone Analysis (5 Dimensionen), GFK-Analyse, Cognitive Distortion Detection (7 Typen), Four-Sides Model Analysis, Topic Classification (7 Kategorien). Desktop-App (Tauri 2.0), Hotkey-Aktivierung (Ctrl+Shift+D), lokale Verarbeitung bevorzugt (Whisper, Ollama), GDPR-konform.",
    keywords: [
      "hablara",
      "voice intelligence",
      "self-reflection",
      "desktop app",
      "tauri",
      "emotion",
      "fallacy",
      "hotkey",
      "strg shift d",
      "ctrl shift d",
    ],
  },
  {
    id: "general_emotion_analysis_overview",
    category: "general",
    title: "Dual-Track Emotion Analysis",
    content:
      "Hablará nutzt Dual-Track Emotion Analysis: 1) Audio-Track (40%): 12 Features wie Pitch, Energy, Speech Rate. 2) Text-Track (60%): LLM-Analyse basierend auf Wortwahl. Fusion: Bei Übereinstimmung wird Confidence geboostet. Dual-Track Analyse (Audio 40% + Text 60%).",
    keywords: [
      "dual track",
      "audio text",
      "fusion",
      "confidence boost",
      "accuracy",
      "12 features",
    ],
  },
  {
    id: "general_audio_features",
    category: "general",
    title: "12 Audio Features für Emotion Detection",
    content:
      "Prosodic (5): Pitch, Energy, Speech Rate, Pitch Variance, Energy Variance, Pause Duration/Frequency. Spectral (4): ZCR, Spectral Centroid, Rolloff, Flux. Key Unterscheidungen: Spectral Flux (harsh) = Aggression vs. Excitement. Pitch Variance (instabil) = Stress vs. Excitement (stabil). Dual-Track Analyse (Audio 40% + Text 60%).",
    keywords: [
      "audio features",
      "prosodic",
      "spectral",
      "pitch variance",
      "spectral flux",
      "zcr",
      "emotion detection",
      "12 features",
      "stress excitement",
      "aggression",
    ],
  },
  {
    id: "general_multi_modal_analysis",
    category: "general",
    title: "Was ist Multi-Modal Analysis?",
    content:
      "Multi-Modal Analysis bedeutet, dass Hablará sowohl Audio- als auch Text-Daten nutzt. Audio-Modalität: Prosodische Features (Pitch, Energie, Sprechgeschwindigkeit) und Spektrale Features (ZCR, Spectral Centroid). Text-Modalität: Semantische Analyse via LLM (Wortwahl, Kontext, Marker). Fusion: 40% Audio-Gewicht, 60% Text-Gewicht. Vorteil: Höhere Genauigkeit durch Kombination beider Modalitäten.",
    keywords: [
      "multi modal",
      "audio text",
      "prosodisch",
      "spektral",
      "semantisch",
      "fusion",
      "modalitäten",
      "genauigkeit",
    ],
  },
  {
    id: "general_llm_providers",
    category: "general",
    title: "LLM Providers (3 Options)",
    content:
      "Hablará unterstützt 3 LLM-Provider: 1) Ollama (qwen2.5:7b-custom): Lokal, $0, 2-4s/call, persistent server. Default-Provider. 2) OpenAI (gpt-4o-mini): Cloud, ~$0.0002/analysis, 0.5-2s/call, schnell. 3) Anthropic (claude-sonnet-4): Cloud, ~$0.0024/analysis, 0.5-2s/call, höchste Qualität. API Keys werden OS-nativ verschlüsselt gespeichert (Keychain/Credential Manager). Cloud-Provider erfordern GDPR-Consent.",
    keywords: [
      "llm provider",
      "ollama",
      "openai",
      "anthropic",
      "qwen",
      "gpt-4o-mini",
      "claude-sonnet",
      "lokal",
      "cloud",
      "3 optionen",
    ],
  },
  {
    id: "general_rag_chatbot",
    category: "general",
    title: "Was ist der RAG-Chatbot?",
    content:
      "Der RAG-Chatbot (Retrieval-Augmented Generation) hilft bei Fragen zu Hablará. Architektur: 1) Query -> Keyword-Search -> Top-3 relevante Chunks aus Wissensbasis. 2) Chunks + Chat-Verlauf -> LLM-Prompt. 3) LLM (Ollama/OpenAI/Anthropic) -> Antwort. Wissensbasis: 78 kuratierte Chunks (Emotion, Fallacy, Tone, GFK, Cognitive Distortion, Four-Sides, Topic, General). Offline-fähig (Ollama), faktisch korrekt (RAG verhindert Halluzination).",
    keywords: [
      "rag",
      "chatbot",
      "retrieval augmented generation",
      "wissensbasis",
      "chunks",
      "keyword search",
      "offline",
      "halluzination",
    ],
  },
  {
    id: "general_transcription",
    category: "general",
    title: "Wie funktioniert Transkription?",
    content:
      "Hablará nutzt whisper.cpp (german-turbo) als Default für Speech-to-Text. Pipeline: Native cpal Audio (48kHz) -> Resampling (16kHz) -> VAD Filter (Silero, Threshold 0.3) -> Whisper (german-turbo) -> Text Filter (Filler-Words entfernt) -> Clean Transcript. Optional: MLX-Whisper (3x schneller via Apple MLX, konfigurierbar in Settings). Accuracy: Sehr hoch für deutschsprachige Aufnahmen.",
    keywords: [
      "transkription",
      "whisper",
      "german-turbo",
      "mlx-whisper",
      "speech-to-text",
      "vad",
      "silero",
      "resampling",
    ],
  },
  {
    id: "general_hotkey",
    category: "general",
    title: "Wie nutze ich den Hotkey?",
    content:
      "Hablará wird per Hotkey aktiviert: Ctrl+Shift+D (auf allen Platformen: Windows, Linux, macOS). Workflow: 1) Hotkey drücken -> Aufnahme startet. 2) Sprechen -> LED-Segment-Anzeige zeigt Echtzeit-Pegel (10 Segmente: 6 grün, 2 orange, 2 rot). 3) Hotkey erneut drücken -> Aufnahme stoppt. 4) Automatische Verarbeitung: Transkription -> Emotion/Fallacy/Tone/GFK/Cognitive/FourSides/Topic Analysis -> Ergebnisse in Chat-Historie. Frictionless Capture: Keine Klicks nötig.",
    keywords: [
      "hotkey",
      "strg shift d",
      "ctrl shift d",
      "cmd shift d",
      "aktivierung",
      "aufnahme",
      "frictionless",
      "workflow",
      "led segment anzeige",
      "pegel anzeige",
    ],
  },
  {
    id: "general_gdpr_privacy",
    category: "general",
    title: "Ist Hablará GDPR-konform?",
    content:
      "Ja, Hablará ist GDPR-konform. Datenschutz: 1) Lokale Verarbeitung bevorzugt (Whisper, Ollama) - keine Cloud-Pflicht. 2) Audio-Daten werden nach Verarbeitung gelöscht (kein permanenter Speicher). 3) Cloud-Provider (OpenAI/Anthropic) erfordern explizite Einwilligung (Consent-Modal). 4) API Keys werden OS-nativ verschlüsselt (Keychain/Credential Manager, AES-256-GCM). 5) Keine Telemetrie, kein Tracking. Hablará ist ein Selbstreflexions-Tool (GDPR Art. 6), NICHT Gesundheitsdaten (Art. 9).",
    keywords: [
      "gdpr",
      "datenschutz",
      "privacy",
      "lokal",
      "consent",
      "verschlüsselung",
      "keychain",
      "self-reflection",
      "art 6",
      "compliance",
    ],
  },
  {
    id: "general_gdpr_data_management",
    category: "general",
    title: "GDPR: Welche Daten werden erfasst?",
    content:
      "Welche Daten erfasst Hablará? Audio temporär (nur während Aufnahme), Transkript und Analyse-Metadaten persistent (als JSON), Audio-Features werden berechnet und nach Analyse verworfen. Datenfluss bei Cloud-Providern: Nur der Transkript-Text wird an OpenAI/Anthropic gesendet, Audio bleibt immer lokal. Alle Daten löschen: Settings -> Clear All oder Speicherordner manuell löschen. Consent-Widerruf: Jederzeit zu Ollama (lokal) zurückwechseln.",
    keywords: [
      "gdpr",
      "welche daten",
      "daten erfasst",
      "cloud daten",
      "datenfluss",
      "alle daten löschen",
      "löschen",
      "widerruf",
      "consent",
      "audio lokal",
    ],
  },
  {
    id: "general_getting_started",
    category: "general",
    title: "Erste Schritte mit Hablará",
    content:
      "So startest du mit Hablará: 1) App öffnen - die Desktop-App startet automatisch mit Tauri. 2) Hotkey drücken (Ctrl+Shift+D auf allen Platformen) - die Aufnahme beginnt sofort. 3) Sprechen - die LED-Segment-Anzeige zeigt dir den Pegel in Echtzeit (10 Segmente: 6 grün, 2 orange, 2 rot). 4) Hotkey erneut drücken - Aufnahme stoppt, automatische Analyse startet. 5) Ergebnisse ansehen - Transkription, Emotion, Fehlschlüsse, Tonalität, GFK, Kognitive Verzerrungen, Vier-Seiten-Modell und Topic erscheinen in der Chat-Historie. Du brauchst nur den Hotkey - alles andere läuft automatisch.",
    keywords: [
      "erste schritte",
      "getting started",
      "anfangen",
      "starten",
      "einrichten",
      "setup",
      "neu",
      "beginnen",
      "anleitung",
      "wie funktioniert",
      "benutzen",
      "tutorial",
      "einführung",
    ],
  },
  {
    id: "general_confidence_interpretation",
    category: "general",
    title: "Ergebnisse interpretieren (Confidence)",
    content:
      "Confidence-Werte zeigen die Eindeutigkeit der Analyse, nicht die absolute Richtigkeit. Interpretation: >70% = klare Signale (Audio und Text stimmen überein), 40-70% = gemischte Signale (möglicherweise Emotion Blending), <40% = uneindeutig (kurze Aufnahme oder leise Stimme). Hablará nutzt Dual-Track Analyse (40% Audio + 60% Text). Bei Übereinstimmung beider Tracks wird Confidence geboostet. Confidence ist keine Wahrscheinlichkeit, sondern misst die Stärke und Konsistenz der erkannten Signale. Bei ähnlicher Confidence für zwei Emotionen wird Emotion Blending angezeigt.",
    keywords: [
      "confidence",
      "prozent",
      "genauigkeit",
      "interpretation",
      "ergebnis",
      "vertrauen",
      "score",
      "bedeutung",
      "wie genau",
      "zuverlässig",
      "accuracy",
      "was bedeutet",
    ],
  },
  {
    id: "general_storage_data",
    category: "general",
    title: "Speicherung und Datenverwaltung",
    content:
      "Hablará speichert alle Daten lokal auf deinem Gerät. Auto-Save: Jede Aufnahme wird automatisch mit Transkription und Analyse-Metadaten als JSON + WAV gespeichert. Recordings Library: Alle Aufnahmen sind in der Bibliothek abrufbar, sortiert nach Datum. Löschen: Einzelne Aufnahmen können über die Bibliothek gelöscht werden, oder alle über Settings -> Clear All. Auto-Cleanup: Älteste Aufnahmen werden bei Überschreitung des Limits automatisch entfernt (konfigurierbar). Speicherort: Application Data Directory des Betriebssystems. Keine Cloud-Speicherung - alle Daten bleiben lokal. Cloud-LLM-Provider: nur Text, kein Audio.",
    keywords: [
      "speicherung",
      "storage",
      "daten",
      "aufnahmen",
      "recordings",
      "löschen",
      "delete",
      "wo gespeichert",
      "ordner",
      "verwalten",
      "bibliothek",
      "library",
      "auto-save",
      "cleanup",
      "aufräumen",
    ],
  },
  {
    id: "general_feature_comparison_emotional",
    category: "general",
    title: "Analyse-Features: Emotion, Tone, Fallacy",
    content:
      "Hablará bietet 3 emotionale/sprachliche Analyse-Features: 1) Emotionserkennung = WAS fühlst du? (10 Emotionstypen, Dual-Track Audio+Text). 2) Tonalitätsanalyse = WIE sprichst du? (5 Dimensionen: Formalität, Professionalität, Direktheit, Energie, Ernsthaftigkeit). 3) Fehlschlusserkennung = IST dein Argument logisch? (16 Fehlschlusstypen, CEG-Prompting). Diese Features analysieren deine emotionale Reaktion und sprachliche Form.",
    keywords: [
      "emotion",
      "tone",
      "fallacy",
      "fehlschluss",
      "emotionserkennung",
      "tonalität",
      "features",
      "analyse arten",
      "was fühle ich",
      "wie spreche ich",
    ],
  },
  {
    id: "general_feature_comparison_reflective",
    category: "general",
    title: "Analyse-Features: GFK, Kognitive Verzerrungen, Vier-Seiten",
    content:
      "Hablará bietet 3 reflektive Analyse-Features: 1) GFK (Gewaltfreie Kommunikation) = WIE besser kommunizieren? (Beobachtung, Gefühl, Bedürfnis, Bitte nach Rosenberg 1999/2003). 2) Kognitive Verzerrungen = WIE denkst du? (7 Denkfehler nach Beck 1976, z.B. Katastrophisierung, mit Reframing-Vorschlägen). 3) Vier-Seiten-Modell = WAS sagt deine Aussage auf 4 Ebenen? (Sachinhalt, Selbstoffenbarung, Beziehung, Appell nach Schulz von Thun 1981). Diese Features helfen dir, deine Kommunikation zu reflektieren und zu verbessern.",
    keywords: [
      "gfk",
      "gfk",
      "kognitive verzerrungen",
      "vier seiten",
      "gewaltfreie kommunikation",
      "denkfehler",
      "kommunikationsmodell",
      "reflexion",
      "features",
      "wie denke ich",
    ],
  },
  {
    id: "general_provider_decision",
    category: "general",
    title: "Welchen LLM-Provider wählen?",
    content:
      "Entscheidungshilfe für den LLM-Provider: Ollama (Standard): Komplett lokal, kostenlos, offline-fähig, 2-4 Sekunden pro Analyse. Ideal für Privatsphäre und ohne Internetabhängigkeit. Voraussetzung: Ollama installiert mit qwen2.5:7b Modell. OpenAI (gpt-4o-mini): Cloud-basiert, sehr schnell (0.5-2s), günstig. Ideal für Geschwindigkeit. Anthropic (claude-sonnet-4): Cloud-basiert, höchste Analysequalität, 0.5-2s. Ideal für beste Ergebnisse. Faustregel: Starte mit Ollama (Standard). Wechsle zu OpenAI für Geschwindigkeit oder Anthropic für maximale Qualität. Cloud-Provider erfordern API-Key und GDPR-Einwilligung.",
    keywords: [
      "provider",
      "wählen",
      "auswählen",
      "ollama",
      "openai",
      "anthropic",
      "welcher",
      "empfehlung",
      "lokal",
      "cloud",
      "kostenlos",
      "kosten",
      "offline",
      "schnell",
      "qualität",
    ],
  },
  {
    id: "general_text_audio_import",
    category: "general",
    title: "Text und Audio-Datei Import",
    content:
      "Hablará kann neben Live-Aufnahmen auch Text und Audio-Dateien analysieren. Text-Import: Über das Textarea-Feld kannst du Text direkt einfügen oder aus der Zwischenablage kopieren. Bei Text-Import erfolgt nur Text-basierte Analyse (Emotion, Fallacy, Tone, GFK, Kognitive Verzerrungen, Vier-Seiten, Topic) - kein Audio-Track. Audio-Import: Unterstützt WAV, MP3, AAC, FLAC. Bei Audio-Import erfolgt die vollständige Dual-Track-Analyse (Audio + Text). Alle Ergebnisse erscheinen wie gewohnt in der Chat-Historie und werden gespeichert.",
    keywords: [
      "text import",
      "audio import",
      "datei",
      "file",
      "textarea",
      "clipboard",
      "einfügen",
      "hochladen",
      "upload",
      "ohne aufnahme",
      "wav",
      "mp3",
      "analysieren",
      "text analysieren",
    ],
  },
  {
    id: "general_personalized_reflection",
    category: "general",
    title: "Personalisiertes Feedback (Baseline)",
    content:
      "Hablará lernt deine typischen Muster und gibt personalisiertes Feedback. Baseline-System: Cold Start (0-4 Aufnahmen): Allgemeines Feedback ohne persönlichen Bezug. Preliminary (5-9 Aufnahmen): Erste Trends werden erkannt. Personalized (10+ Aufnahmen): Vollständig personalisiertes Feedback basierend auf deiner Baseline. Abweichungen von deinem typischen Muster werden gemeldet (z.B. 'Heute klingst du gestresster als gewöhnlich'). Feedback folgt einem Growth-Mindset-Ansatz: nicht-wertend, entwicklungsorientiert, mit konkreten Reflexionsfragen.",
    keywords: [
      "personalisiert",
      "feedback",
      "baseline",
      "persönlich",
      "reflexion",
      "reflection",
      "muster",
      "trend",
      "veränderung",
      "wachstum",
      "growth",
      "vorher nachher",
    ],
  },
  {
    id: "general_emotion_blending",
    category: "general",
    title: "Emotion Blending (Mischung)",
    content:
      "Emotion Blending zeigt, wenn zwei Emotionen gleichzeitig erkannt werden. Blend Ratio: Die Stärke der sekundären Emotion muss mindestens 40% Confidence erreichen. Maximum: Die sekundäre Emotion kann maximal 50% des Blends ausmachen (Primäre bleibt dominant). Beispiel: 57% Excitement + 43% Stress. UI-Darstellung: Stacked Bars zeigen das Verhältnis als farbige Balken. Der Circumplex Diamond (gelber Diamant) zeigt die Blend-Position im 2D-Raum (Valence x Arousal). Basiert auf Plutchik's Wheel of Emotions und Russell's Circumplex Model.",
    keywords: [
      "blending",
      "mischung",
      "blend",
      "gemischt",
      "zwei emotionen",
      "prozent",
      "verhältnis",
      "stacked bars",
      "circumplex",
      "diamond",
      "sekundär",
      "primary secondary",
    ],
  },
  {
    id: "general_export",
    category: "general",
    title: "Daten exportieren",
    content:
      "Hablará ermöglicht den Export von Analyse-Ergebnissen. Markdown-Export: Vollständiger Export mit YAML-Frontmatter und allen Analyse-Ergebnissen (Emotion, Fallacy, Tone, GFK, Kognitive Verzerrungen, Vier-Seiten, Topic). Plain-Text-Export: Transkription und Kernanalyse im Textformat. Enthalten sind: Transkription, erkannte Emotionen, Fehlschlüsse, Tonalitäts-Werte, GFK-Analyse, Kognitive Verzerrungen, Vier-Seiten-Analyse und Topic-Kategorie. Nutzung: Zum Archivieren, Teilen oder Importieren in andere Tools.",
    keywords: [
      "export",
      "exportieren",
      "herunterladen",
      "download",
      "markdown",
      "text",
      "speichern extern",
      "teilen",
      "share",
      "datei export",
      "kopieren",
    ],
  },
  {
    id: "general_troubleshooting_transcription_emotion",
    category: "general",
    title: "Probleme: Transkription und Emotion ungenau",
    content:
      "Transkription ungenau? Deutlich und nah am Mikrofon sprechen, Hintergrundgeräusche minimieren. whisper.cpp german-turbo ist optimiert für deutschsprachige Aufnahmen. Bei sehr kurzen Aufnahmen (<3 Sekunden) kann die Genauigkeit sinken. Emotion falsch erkannt? Kurze Aufnahmen (<5 Sekunden) haben weniger Audio-Features. Hintergrundlärm kann Audio-Track verfälschen. Mehr Kontext (längere Aufnahmen) verbessert die Erkennung.",
    keywords: [
      "transkription falsch",
      "transkription ungenau",
      "emotion falsch",
      "emotion ungenau",
      "whisper",
      "genauigkeit",
      "problem",
      "hilfe",
      "lösung",
      "kurze aufnahme",
    ],
  },
  {
    id: "general_troubleshooting_audio_llm",
    category: "general",
    title: "Probleme: Kein Audio oder LLM antwortet nicht",
    content:
      "Kein Audio aufgenommen? Mikrofon-Berechtigung in Systemeinstellungen prüfen. Die LED-Segment-Anzeige sollte bei Sprache ausschlagen (10 Segmente: 6 grün, 2 orange, 2 rot für laute Bereiche). Falls die Anzeige nicht reagiert, ist kein Mikrofon aktiv. LLM antwortet nicht? Bei Ollama: 'ollama serve' im Terminal prüfen, Server muss laufen. Bei Cloud-Providern (OpenAI/Anthropic): API-Key in Settings korrekt eingegeben? Internetverbindung aktiv?",
    keywords: [
      "kein audio",
      "kein ton",
      "mikrofon",
      "llm antwortet nicht",
      "ollama",
      "openai",
      "anthropic",
      "problem",
      "hilfe",
      "lösung",
      "api key",
    ],
  },
  {
    id: "general_analysis_features_overview",
    category: "general",
    title: "Welche Analysefunktionen gibt es?",
    content:
      "Hablará bietet **7 KI-gestützte Analysefunktionen**: 1) **Emotion Detection** (10 Typen): Dual-Track Analyse (Audio 40% + Text 60%) erkennt Neutral, Ruhig, Stress, Aufregung, Unsicherheit, Frustration, Freude, Zweifel, Überzeugung, Aggression. 2) **Fallacy Detection** (16 Typen): Erkennt logische Fehlschlüsse wie Ad Hominem, Strohmann, Falsches Dilemma, etc. 3) **Tone Analysis** (5 Dimensionen): Bewertet Formalität, Professionalität, Direktheit, Energie, Ernsthaftigkeit (Skala 1-5). 4) **GFK-Analyse**: Gewaltfreie Kommunikation nach Rosenberg - Beobachtungen, Gefühle, Bedürfnisse, Bitten. 5) **Cognitive Distortion Detection** (7 Typen): CBT-basierte Erkennung kognitiver Verzerrungen (Schwarz-Weiß-Denken, Katastrophisierung, etc.). 6) **Four-Sides Model Analysis**: Schulz von Thun - Sachinhalt, Selbstoffenbarung, Beziehung, Appell. 7) **Topic Classification** (7 Kategorien): Kategorisiert Aufnahmen in Arbeit/Karriere, Gesundheit, Beziehungen, Finanzen, Entwicklung, Kreativität, Sonstiges. Alle Analysen sind LLM-gestützt (Ollama/OpenAI/Anthropic wählbar) und in Settings aktivierbar.",
    keywords: [
      "analysefunktionen",
      "funktionen",
      "features",
      "analyse",
      "übersicht",
      "was kann hablara",
      "alle funktionen",
      "emotion",
      "fallacy",
      "tone",
      "gfk",
      "cognitive",
      "four sides",
      "topic",
      "7 funktionen",
    ],
  },
];
